{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
    "num_songs = 100\n",
    "sr = 22050\n",
    "Y_LIMIT = 660000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        np.random.seed(1)\n",
    "        self.X_mfcc = None\n",
    "        self.X_mfcc_random_crop = None\n",
    "        self.X_mfcc_fixed_crop = None\n",
    "        \n",
    "        self.X_chroma = None\n",
    "        self.X_chroma_random_crop = None\n",
    "        self.X_chroma_fixed_crop = None\n",
    "        \n",
    "        self.Y = None\n",
    "        self.Y_crop = None\n",
    "        \n",
    "        self.SEG = 10   # Must evenly divide 30\n",
    "        self.SEG_LENGTH = int(1290/self.SEG)\n",
    "        self.RANDOM_SEG_LENGTH = 1200\n",
    "        self.RANDOM_STARTS = np.random.randint(low=0, high=1290-self.RANDOM_SEG_LENGTH, size=(1000, self.SEG))\n",
    "        \n",
    "        self.train_idxs = np.sort(np.random.choice(np.array([i for i in range(1000)]), size=750, replace=False))\n",
    "        self.test_idxs = np.array([i for i in range(1000) if i not in self.train_idxs])\n",
    "        \n",
    "        self.train_crop_idxs = np.hstack([np.array([i*self.SEG+j for j in range(self.SEG)]) for i in self.train_idxs])\n",
    "        self.test_crop_idxs = np.hstack([np.array([i*self.SEG+j for j in range(self.SEG)]) for i in self.test_idxs])\n",
    "        \n",
    "    def save_mfcc(self, genres=all_genres, songs=num_songs):\n",
    "        '''\n",
    "        Saves MFCC Coefficients.\n",
    "        Produces a 1000 x 16770 array.\n",
    "        '''\n",
    "        assert(self.X_mfcc is None)\n",
    "        X_mfcc = None\n",
    "        for g_idx, g in enumerate(genres):\n",
    "            for s_idx in range(songs):\n",
    "                y, sr = librosa.load(f'genres/{g}/{g}.000{s_idx:02d}.wav')\n",
    "                y = y[:Y_LIMIT]\n",
    "                mfcc = librosa.feature.mfcc(y, sr=sr, hop_length=512, n_mfcc=13).flatten()\n",
    "                if X_mfcc is None:\n",
    "                    X_mfcc = mfcc.reshape(1, mfcc.shape[0])\n",
    "                else:\n",
    "                    X_mfcc = np.vstack([X_mfcc, mfcc])\n",
    "        scaler = StandardScaler()\n",
    "        self.X_mfcc = scaler.fit_transform(X_mfcc)\n",
    "        np.savetxt('data/X_mfcc.csv', self.X_mfcc)\n",
    "    \n",
    "    def save_mfcc_random_crop(self):\n",
    "        '''\n",
    "        Saves 10 random crops of MFCC for every original training sample.\n",
    "        Produces a 10000 x 13 x 1200 array, padded to 10000 x 13 x 1290.\n",
    "        Reshapes into 10000*16770 for the CSV.\n",
    "        '''\n",
    "        assert(self.X_mfcc_random_crop is None and self.X_mfcc is not None)\n",
    "        X_mfcc_crop = None\n",
    "        for i, mfcc in enumerate(self.X_mfcc):\n",
    "            crop = None\n",
    "            for j in range(self.SEG):\n",
    "                random_start = self.RANDOM_STARTS[i][j]\n",
    "                random_seg = np.vstack([mfcc[1290*k+random_start : 1290*k+random_start+self.RANDOM_SEG_LENGTH] for k in range(13)])\n",
    "                random_seg = random_seg.reshape(1, random_seg.shape[0], random_seg.shape[1])\n",
    "                if crop is None:\n",
    "                    crop = random_seg\n",
    "                else:\n",
    "                    crop = np.vstack([crop, random_seg])\n",
    "            if X_mfcc_crop is None:\n",
    "                X_mfcc_crop = crop\n",
    "            else:\n",
    "                X_mfcc_crop = np.vstack([X_mfcc_crop, crop])\n",
    "        self.X_mfcc_random_crop = X_mfcc_crop\n",
    "        np.savetxt('data/X_mfcc_random_crop.csv', X_mfcc_crop.reshape(1000*self.SEG, 13*self.RANDOM_SEG_LENGTH))\n",
    "    \n",
    "    def save_mfcc_fixed_crop(self):\n",
    "        '''\n",
    "        Saves 10 even segments of MFCC for every original training sample.\n",
    "        Produces a 10000 x 13 x 129 array of MFCC coefficients for the segments.\n",
    "        Reshapes into 10000*1677 for the CSV.\n",
    "        '''\n",
    "        assert(self.X_mfcc_fixed_crop is None and self.X_mfcc is not None)\n",
    "        X_mfcc_crop = None\n",
    "        for mfcc in self.X_mfcc:\n",
    "            crop = np.stack([np.vstack([mfcc[1290*j+self.SEG_LENGTH*i : 1290*j+self.SEG_LENGTH*(i+1)] for j in range(13)]) for i in range(self.SEG)], axis=0)\n",
    "            if X_mfcc_crop is None:\n",
    "                X_mfcc_crop = crop\n",
    "            else:\n",
    "                X_mfcc_crop = np.vstack([X_mfcc_crop, crop])\n",
    "        self.X_mfcc_fixed_crop = X_mfcc_crop\n",
    "        np.savetxt('data/X_mfcc_fixed_crop.csv', X_mfcc_crop.reshape(1000*self.SEG, 13*self.SEG_LENGTH))\n",
    "    \n",
    "    def save_chroma(self, genres=all_genres, songs=num_songs):\n",
    "        '''\n",
    "        Saves Chromas.\n",
    "        Produces a 1000 x 15480 array.\n",
    "        '''\n",
    "        assert(self.X_chroma is None)\n",
    "        X_chroma = None\n",
    "        for g_idx, g in enumerate(genres):\n",
    "            for s_idx in range(songs):\n",
    "                y, sr = librosa.load(f'genres/{g}/{g}.000{s_idx:02d}.wav')\n",
    "                y = y[:Y_LIMIT]\n",
    "                chroma = librosa.feature.chroma_cqt(y, sr=sr, hop_length=512).flatten()\n",
    "                if X_chroma is None:\n",
    "                    X_chroma = chroma.reshape(1, chroma.shape[0])\n",
    "                else:\n",
    "                    X_chroma = np.vstack([X_chroma, chroma])\n",
    "        scaler = StandardScaler()\n",
    "        self.X_chroma = scaler.fit_transform(X_chroma)\n",
    "        np.savetxt('data/X_chroma.csv', self.X_chroma)\n",
    "\n",
    "    def save_chroma_random_crop(self):\n",
    "        '''\n",
    "        Saves 10 random crops of Chromas for every original training sample.\n",
    "        Produces a 10000 x 12 x 1200 array, padded to 10000 x 12 x 1290.\n",
    "        Reshapes into 10000*15480 for the CSV.\n",
    "        '''\n",
    "        assert(self.X_chroma_random_crop is None and self.X_chroma is not None)\n",
    "        X_chroma_crop = None\n",
    "        for i, chroma in enumerate(self.X_chroma):\n",
    "            crop = None\n",
    "            for j in range(self.SEG):\n",
    "                random_start = self.RANDOM_STARTS[i][j]\n",
    "                random_seg = np.vstack([chroma[1290*k+random_start : 1290*k+random_start+self.RANDOM_SEG_LENGTH] for k in range(12)])\n",
    "                random_seg = random_seg.reshape(1, random_seg.shape[0], random_seg.shape[1])\n",
    "                if crop is None:\n",
    "                    crop = random_seg\n",
    "                else:\n",
    "                    crop = np.vstack([crop, random_seg])\n",
    "            if X_chroma_crop is None:\n",
    "                X_chroma_crop = crop\n",
    "            else:\n",
    "                X_chroma_crop = np.vstack([X_chroma_crop, crop])\n",
    "        self.X_chroma_random_crop = X_chroma_crop\n",
    "        np.savetxt('data/X_chroma_random_crop.csv', X_chroma_crop.reshape(1000*self.SEG, 12*self.RANDOM_SEG_LENGTH))\n",
    "        \n",
    "    def save_chroma_fixed_crop(self):\n",
    "        '''\n",
    "        Saves 10 even segments of Chromas for every original training sample.\n",
    "        Produces a 10000 x 12 x 129 array of MFCC coefficients for the segments.\n",
    "        Reshapes into 10000*1548 for the CSV.\n",
    "        '''\n",
    "        assert(self.X_chroma_fixed_crop is None and self.X_chroma is not None)\n",
    "        X_chroma_crop = None\n",
    "        for chroma in self.X_chroma:\n",
    "            crop = np.stack([np.vstack([chroma[1290*j+self.SEG_LENGTH*i : 1290*j+self.SEG_LENGTH*(i+1)] for j in range(12)]) for i in range(self.SEG)], axis=0)\n",
    "            if X_chroma_crop is None:\n",
    "                X_chroma_crop = crop\n",
    "            else:\n",
    "                X_chroma_crop = np.vstack([X_chroma_crop, crop])\n",
    "        self.X_chroma_fixed_crop = X_chroma_crop\n",
    "        np.savetxt('data/X_chroma_fixed_crop.csv', X_chroma_crop.reshape(1000*self.SEG, 12*self.SEG_LENGTH))\n",
    "    \n",
    "    # If X_mfcc has been saved, but we aborted before saving X_mfcc_random_crop (or X_mfcc_fixed_crop),\n",
    "    # we can call load_mfcc with tensor=False to load the MFCC in 2D and then call dl.save_fixed_crop().\n",
    "    \n",
    "    # Note that all load functions reshape into tensors by default.\n",
    "    \n",
    "    def load_mfcc(self, tensor=True):\n",
    "        self.X_mfcc = np.loadtxt('data/X_mfcc.csv')\n",
    "        if tensor:\n",
    "            self.X_mfcc = self.X_mfcc.reshape(1000, 13, 1290)\n",
    "    \n",
    "    def load_mfcc_random_crop(self):\n",
    "        self.X_mfcc_random_crop = np.loadtxt('data/X_mfcc_random_crop.csv').reshape(1000*self.SEG, 13, self.RANDOM_SEG_LENGTH)\n",
    "        \n",
    "    def load_mfcc_fixed_crop(self):\n",
    "        self.X_mfcc_fixed_crop = np.loadtxt('data/X_mfcc_fixed_crop.csv').reshape(1000*self.SEG, 13, self.SEG_LENGTH)\n",
    "        \n",
    "    def load_chroma(self, tensor=True):\n",
    "        self.X_chroma = np.loadtxt('data/X_chroma.csv')\n",
    "        if tensor:\n",
    "            self.X_chroma = self.X_chroma.reshape(1000, 12, 1290)\n",
    "    \n",
    "    def load_chroma_random_crop(self):\n",
    "        self.X_chroma_random_crop = np.loadtxt('data/X_chroma_random_crop.csv').reshape(1000*self.SEG, 12, self.RANDOM_SEG_LENGTH)\n",
    "        \n",
    "    def load_chroma_fixed_crop(self):\n",
    "        self.X_chroma_fixed_crop = np.loadtxt('data/X_chroma_fixed_crop.csv').reshape(1000*self.SEG, 12, self.SEG_LENGTH)\n",
    "    \n",
    "    def load_Y(self):\n",
    "        self.Y = np.array([int(i/100) for i in range(1000)]).ravel()\n",
    "        \n",
    "    def load_Y_crop(self):\n",
    "        self.Y_crop = np.array([int(i/(100 * self.SEG)) for i in range(1000 * self.SEG)]).ravel()\n",
    "        \n",
    "    def train_test_split(self, data, is_cropped=True):\n",
    "        if is_cropped:\n",
    "            return np.take(data, self.train_crop_idxs, 0), np.take(data, self.test_crop_idxs, 0)\n",
    "        else:\n",
    "            return np.take(data, self.train_idxs, 0), np.take(data, self.test_idxs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-b19f7b5d9d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # Saves features to data/...  (run once!!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_mfcc_fixed_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_mfcc_random_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-6de43c2a975d>\u001b[0m in \u001b[0;36msave_mfcc\u001b[0;34m(self, genres, songs)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'genres/{g}/{g}.000{s_idx:02d}.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_LIMIT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mX_mfcc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mX_mfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/6.867/yes/envs/py37/lib/python3.7/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/6.867/yes/envs/py37/lib/python3.7/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   1815\u001b[0m     S, n_fft = _spectrogram(y=y, S=S, n_fft=n_fft, hop_length=hop_length, power=power,\n\u001b[1;32m   1816\u001b[0m                             \u001b[0mwin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                             pad_mode=pad_mode)\n\u001b[0m\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;31m# Build a Mel filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/6.867/yes/envs/py37/lib/python3.7/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2526\u001b[0m         S = np.abs(stft(y, n_fft=n_fft, hop_length=hop_length,\n\u001b[1;32m   2527\u001b[0m                         \u001b[0mwin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2528\u001b[0;31m                         window=window, pad_mode=pad_mode))**power\n\u001b[0m\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/6.867/yes/envs/py37/lib/python3.7/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    238\u001b[0m         stft_matrix[:, bl_s:bl_t] = fft.rfft(fft_window *\n\u001b[1;32m    239\u001b[0m                                              \u001b[0my_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbl_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                                              axis=0)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstft_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/6.867/yes/envs/py37/lib/python3.7/site-packages/mkl_fft/_numpy_fft.py\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmkl_fft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfft_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munitary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Saves features to data/...  (run once!!)\n",
    "dl = DataLoader()\n",
    "dl.save_mfcc()\n",
    "dl.save_mfcc_fixed_crop()\n",
    "dl.save_mfcc_random_crop()\n",
    "dl.save_chroma()\n",
    "dl.save_chroma_fixed_crop()\n",
    "dl.save_chroma_random_crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load from CSVs in data/...\n",
    "dl = DataLoader()\n",
    "dl.load_mfcc()\n",
    "dl.load_mfcc_fixed_crop()\n",
    "dl.load_mfcc_random_crop()\n",
    "dl.load_chroma()\n",
    "dl.load_chroma_fixed_crop()\n",
    "dl.load_chroma_random_crop()\n",
    "dl.load_Y()\n",
    "dl.load_Y_crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 13, 1290),\n",
       " (10000, 13, 1200),\n",
       " (10000, 13, 129),\n",
       " (1000, 12, 1290),\n",
       " (10000, 12, 1200),\n",
       " (10000, 12, 129))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.X_mfcc.shape, dl.X_mfcc_random_crop.shape, dl.X_mfcc_fixed_crop.shape, dl.X_chroma.shape, dl.X_chroma_random_crop.shape, dl.X_chroma_fixed_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (10000,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.Y.shape, dl.Y_crop.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
