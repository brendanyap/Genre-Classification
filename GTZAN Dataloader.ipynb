{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
    "num_songs = 100\n",
    "sr = 22050\n",
    "Y_LIMIT = 660000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.X_mfcc = None\n",
    "        self.X_mfcc_pca = None\n",
    "        self.X_mfcc_random_crop = None\n",
    "        self.X_mfcc_fixed_crop = None\n",
    "        self.X_chroma = None\n",
    "        self.X_chroma_pca = None\n",
    "        self.pca_mfcc = None\n",
    "        self.pca_chroma = None\n",
    "        self.Y = None\n",
    "        \n",
    "    def save_raw(self, genres=all_genres, songs=num_songs):\n",
    "        assert(self.X is None and self.Y is None)\n",
    "        X, Y = None, None\n",
    "        for g_idx, g in enumerate(genres):\n",
    "            for s_idx in range(songs):\n",
    "                y, sr = librosa.load(f'genres/{g}/{g}.000{s_idx:02d}.wav')\n",
    "                y = y[:Y_LIMIT]\n",
    "                if X is None:\n",
    "                    X = y.reshape(1, y.shape[0])\n",
    "                    Y = np.array([[g_idx]])\n",
    "                else:\n",
    "                    X = np.vstack([X, y])\n",
    "                    Y = np.vstack([Y, np.array([[g_idx]])])\n",
    "        Y = Y.ravel()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        np.savetxt('data/X.csv', X)\n",
    "        np.savetxt('data/Y.csv', Y)\n",
    "        \n",
    "    def save_mfcc(self, genres=all_genres, songs=num_songs):\n",
    "        assert(self.X_mfcc is None)\n",
    "        X_mfcc = None\n",
    "        for g_idx, g in enumerate(genres):\n",
    "            for s_idx in range(songs):\n",
    "                y, sr = librosa.load(f'genres/{g}/{g}.000{s_idx:02d}.wav')\n",
    "                y = y[:Y_LIMIT]\n",
    "                mfcc = librosa.feature.mfcc(y, sr=sr, hop_length=512, n_mfcc=13).flatten()\n",
    "                if X_mfcc is None:\n",
    "                    X_mfcc = mfcc.reshape(1, mfcc.shape[0])\n",
    "                else:\n",
    "                    X_mfcc = np.vstack([X_mfcc, mfcc])\n",
    "        self.X_mfcc = X_mfcc\n",
    "        np.savetxt('data/X_mfcc.csv', X_mfcc)\n",
    "        \n",
    "    def save_mfcc_pca(self, pca_dims=100):\n",
    "        assert(self.X_mfcc_pca is None and self.pca_mfcc is None)\n",
    "        pca_mfcc = PCA(n_components=pca_dims, random_state=1)\n",
    "        X_mfcc_pca = pca_mfcc.fit_transform(self.X_mfcc)\n",
    "        self.pca_mfcc = pca_mfcc\n",
    "        self.X_mfcc_pca = X_mfcc_pca\n",
    "        np.savetxt(f'data/X_mfcc_pca{pca_dims}.csv', X_mfcc_pca)\n",
    "        dump(pca_mfcc, f'data/pca_mfcc{pca_dims}.PCA') \n",
    "    \n",
    "    def save_mfcc_random_crop(self):\n",
    "        X_mfcc_crop = None\n",
    "        for mfcc in self.X_mfcc:\n",
    "            crop = None\n",
    "            SEG = 10\n",
    "            SEG_LENGTH = 129\n",
    "            for j in range(SEG):\n",
    "                random_start = np.random.randint(0, 1290-SEG_LENGTH)\n",
    "                random_seg = np.vstack([mfcc[1290*j+random_start : 1290*j+random_start+SEG_LENGTH] for j in range(13)])\n",
    "                random_seg = random_seg.reshape(1, random_seg.shape[0], random_seg.shape[1])\n",
    "                if crop is None:\n",
    "                    crop = random_seg\n",
    "                else:\n",
    "                    crop = np.vstack([crop, random_seg])\n",
    "            if X_mfcc_crop is None:\n",
    "                X_mfcc_crop = crop\n",
    "            else:\n",
    "                X_mfcc_crop = np.vstack([X_mfcc_crop, crop])\n",
    "        self.X_mfcc_random_crop = X_mfcc_crop\n",
    "        np.savetxt('data/X_mfcc_random_crop.csv', X_mfcc_crop.reshape(10000, 1677))\n",
    "    \n",
    "    def save_mfcc_fixed_crop(self):\n",
    "        '''\n",
    "        Evenly divides each song into 10 segments,\n",
    "        producing a 10000 by 13 by 129 array of MFCC coefficients for the segments.\n",
    "        Reshapes into 10000*1677 in order to save as a CSV.\n",
    "        '''\n",
    "        X_mfcc_crop = None\n",
    "        for mfcc in self.X_mfcc:\n",
    "            SEG = 10\n",
    "            SEG_LENGTH = int(1290/SEG)\n",
    "            i = 0\n",
    "            crop = np.stack([np.vstack([mfcc[1290*j+SEG_LENGTH*i : 1290*j+SEG_LENGTH*(i+1)] for j in range(13)]) for i in range(SEG)], axis=0)\n",
    "            if X_mfcc_crop is None:\n",
    "                X_mfcc_crop = crop\n",
    "            else:\n",
    "                X_mfcc_crop = np.vstack([X_mfcc_crop, crop])\n",
    "        self.X_mfcc_fixed_crop = X_mfcc_crop\n",
    "        np.savetxt('data/X_mfcc_fixed_crop.csv', X_mfcc_crop.reshape(10000, 1677))\n",
    "    \n",
    "    def save_chroma(self, genres=all_genres, songs=num_songs):\n",
    "        assert(self.X_chroma is None)\n",
    "        X_chroma = None\n",
    "        for g_idx, g in enumerate(genres):\n",
    "            for s_idx in range(songs):\n",
    "                y, sr = librosa.load(f'genres/{g}/{g}.000{s_idx:02d}.wav')\n",
    "                y = y[:Y_LIMIT]\n",
    "                chroma = librosa.feature.chroma_cqt(y, sr=sr, hop_length=512).flatten()\n",
    "                if X_chroma is None:\n",
    "                    X_chroma = chroma.reshape(1, chroma.shape[0])\n",
    "                else:\n",
    "                    X_chroma = np.vstack([X_chroma, chroma])\n",
    "        self.X_chroma = X_chroma\n",
    "        np.savetxt('data/X_chroma.csv', X_chroma)\n",
    "    \n",
    "    def save_chroma_pca(self, pca_dims=100):\n",
    "        assert(self.X_chroma_pca is None and self.pca_chroma is None)\n",
    "        pca_chroma = PCA(n_components=pca_dims)\n",
    "        X_chroma_pca = pca_chroma.fit_transform(self.X_chroma, random_state=1)\n",
    "        self.pca_chroma = pca_chroma\n",
    "        self.X_chroma_pca = X_chroma_pca\n",
    "        np.savetxt(f'data/X_chroma_pca{pca_dims}.csv', X_chroma_pca)\n",
    "        dump(pca_chroma, f'data/pca_chroma{pca_dims}.PCA') \n",
    "    \n",
    "    def load_raw(self):\n",
    "        self.X_raw = np.loadtxt('data/X.csv')\n",
    "        \n",
    "    def load_mfcc(self):\n",
    "        self.X_mfcc = np.loadtxt('data/X_mfcc.csv')\n",
    "    \n",
    "    def load_mfcc_random_crop(self):\n",
    "        self.X_mfcc_random_crop = np.loadtxt('data/X_mfcc_random_crop.csv').reshape(10000, 13, 129)\n",
    "        \n",
    "    def load_mfcc_fixed_crop(self):\n",
    "        self.X_mfcc_fixed_crop = np.loadtxt('data/X_mfcc_fixed_crop.csv').reshape(10000, 13, 129)\n",
    "        \n",
    "    def load_mfcc(self):\n",
    "        self.X_mfcc = np.loadtxt('data/X_mfcc.csv')\n",
    "        \n",
    "    def load_mfcc_pca(self, pca_dims=100):\n",
    "        self.X_mfcc_pca = np.loadtxt(f'data/X_mfcc_pca{pca_dims}.csv')\n",
    "        self.pca_mfcc = load(f'data/pca_mfcc{pca_dims}.PCA')\n",
    "        \n",
    "    def load_chroma(self):\n",
    "        self.X_chroma = np.loadtxt('data/X_chroma.csv')\n",
    "    \n",
    "    def load_chroma_pca(self, pca_dims=100):\n",
    "        self.X_chroma_pca = np.loadtxt(f'data/X_chroma_pca{pca_dims}.csv')\n",
    "        self.pca_chroma = load(f'data/pca_chroma{pca_dims}.PCA') \n",
    "    \n",
    "    def load_Y(self):\n",
    "        self.Y = np.loadtxt('data/Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f3447402acb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_mfcc_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_chroma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_chroma_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-8f62bfb00d71>\u001b[0m in \u001b[0;36msave_chroma_pca\u001b[1;34m(self, pca_dims)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_chroma_pca\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpca_chroma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mpca_chroma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpca_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mX_chroma_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_chroma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_chroma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpca_chroma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_chroma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_chroma_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_chroma_pca\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_transform() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "# # Only need to run this ONCE!\n",
    "# # Saves features and pca objects to data/...\n",
    "# dl = DataLoader()\n",
    "# dl.save_raw(genres=all_genres, songs=100)\n",
    "# dl.save_mfcc()\n",
    "# dl.save_mfcc_pca()\n",
    "# dl.save_chroma()\n",
    "# dl.save_chroma_pca()\n",
    "# dl.save_mfcc_fixed_crop()\n",
    "# dl.save_mfcc_random_crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from CSVs instead of saving\n",
    "dl = DataLoader()\n",
    "dl.load_mfcc()\n",
    "dl.load_mfcc_pca()\n",
    "dl.load_mfcc_random_crop()\n",
    "dl.load_mfcc_fixed_crop()\n",
    "# dl.load_chroma()\n",
    "# dl.load_chroma_pca()\n",
    "# dl.load_Y()\n",
    "# print(dl.X_mfcc.shape, dl.X_mfcc_pca.shape, dl.X_chroma.shape, dl.X_chroma_pca.shape, dl.Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only need to run this ONCE!\n",
    "# Generates train and test indexes among the 1000 datapoints\n",
    "# x = np.array([i for i in range(1000)])\n",
    "# np.random.seed(1)\n",
    "# train_idxs = np.random.choice(x, size=750, replace=False)\n",
    "# train_idxs.sort()\n",
    "# test_idxs = []\n",
    "# for i in range(1000):\n",
    "#     if i not in train_idxs:\n",
    "#         test_idxs.append(i)\n",
    "# test_idxs = np.array(test_idxs)\n",
    "# np.savetxt('data/train_idxs.csv', train_idxs)\n",
    "# np.savetxt('data/test_idxs.csv', test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 993\n"
     ]
    }
   ],
   "source": [
    "# Load the train/test indexes instead of shuffling\n",
    "train_idxs = np.loadtxt('data/train_idxs.csv').astype(int)\n",
    "test_idxs = np.loadtxt('data/test_idxs.csv').astype(int)\n",
    "print(train_idxs[-1], test_idxs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 16770) (250, 16770)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "MX = scaler.fit_transform(dl.X_mfcc)\n",
    "MX_train, MX_test = np.take(MX, train_idxs, 0), np.take(MX, test_idxs, 0)\n",
    "print(MX_train.shape, MX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 15480) (250, 15480)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "CX = scaler.fit_transform(dl.X_chroma)\n",
    "CX_train, CX_test = np.take(CX, train_idxs, 0), np.take(CX, test_idxs, 0)\n",
    "print(CX_train.shape, CX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 32250) (250, 32250)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = np.hstack([dl.X_mfcc, dl.X_chroma])\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test = np.take(X, train_idxs, 0), np.take(X, test_idxs, 0)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 200) (250, 200)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "PX = np.hstack([dl.X_mfcc_pca, dl.X_chroma_pca])\n",
    "PX = scaler.fit_transform(PX)\n",
    "PX_train, PX_test = np.take(PX, train_idxs, 0), np.take(PX, test_idxs, 0)\n",
    "print(PX_train.shape, PX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750,) (250,)\n"
     ]
    }
   ],
   "source": [
    "Y = dl.Y\n",
    "Y_train, Y_test = np.take(Y, train_idxs, 0), np.take(Y, test_idxs, 0)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
